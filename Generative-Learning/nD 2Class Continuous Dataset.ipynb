{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2. nD 2Class Continuous - Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "%matplotlib inline\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from __future__ import division\n",
    "t=np.seterr(divide='ignore', invalid='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Input Dataset ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getData(fileName):\n",
    "    if fileName == 'Breast-Cancer':\n",
    "        with open('breast-cancer-wisconsin.data','r') as f:\n",
    "            records=[]\n",
    "            for line in f:\n",
    "                records.append(line.split(','))\n",
    "        records = records[2:]\n",
    "        dataset = np.array(records).astype(np.int)\n",
    "    elif fileName == 'Iris':\n",
    "        classCount = 2 #Only two classes required\n",
    "        from sklearn import datasets\n",
    "        data = datasets.load_iris() \n",
    "        #data = datasets.load_boston() \n",
    "        #data = datasets.load_diabetes()\n",
    "        X = data['data']\n",
    "        Y = data['target']\n",
    "        Y = Y.reshape(len(data['target']), 1)\n",
    "        dataset = np.hstack((X, Y))\n",
    "    \n",
    "        idx_k=[]\n",
    "        if classCount == 2:\n",
    "            (m, n) = dataset.shape\n",
    "            class_k = np.unique(dataset[:,n-1])\n",
    "            k = len(class_k)\n",
    "            for i in range(classCount):\n",
    "                idx_k.append(filter((lambda x : dataset[:,n-1][x] == class_k[i]), range(m)))\n",
    "            idx_k = np.concatenate((idx_k[0], idx_k[1]), axis=0)\n",
    "            dataset = dataset[idx_k]\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Computing the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getConfusionMatrix(actual, prediction, class_k):\n",
    "    k = len(class_k)\n",
    "    m = len(actual)\n",
    "    cm = np.zeros((k, k))\n",
    "    for i in range(k):\n",
    "        actual_i = filter(lambda x: actual[x] == class_k[i], range(m))\n",
    "        for j in range(k):\n",
    "            predicted_j = filter(lambda x: prediction[x] == class_k[j], range(m))\n",
    "            cm[i,j] = len(np.intersect1d(actual_i, predicted_j))\n",
    "    return cm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Calculating the Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getAccuracy(matrix):\n",
    "    return np.trace(matrix)/np.sum(matrix)\n",
    "\n",
    "def getPrecision(matrix):\n",
    "    k = len(matrix)\n",
    "    precision = np.zeros(k)\n",
    "    for i in range(k):\n",
    "        actual_positives = np.sum(matrix[i])\n",
    "        precision[i] = matrix[i,i]/actual_positives\n",
    "    return precision\n",
    "\n",
    "def getRecall(matrix):\n",
    "    k = len(matrix)\n",
    "    recall = np.zeros(k)\n",
    "    for i in range(k):\n",
    "        predicted_positives = np.sum(matrix[:,i])\n",
    "        recall[i] = matrix[i,i]/predicted_positives\n",
    "    return recall\n",
    "\n",
    "def getFMeasure(precision, recall):\n",
    "    k = len(precision)\n",
    "    fm = np.zeros(k)\n",
    "    for i in range(k):\n",
    "        fm[i] = 2* precision[i]*recall[i]/(precision[i]+recall[i])\n",
    "    return fm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Classifying based on the Membership Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(g, class_k):\n",
    "    (m, n) = g.shape\n",
    "    estimate = np.zeros((m,1))\n",
    "    \n",
    "    for i in range(m):\n",
    "            estimate[i] = class_k[np.argmax(g[i])]\n",
    "            \n",
    "    return estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Computing the Membership Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeMembership(X, modelParam):\n",
    "    (m, n) = X.shape\n",
    "    mean_k = modelParam['mean']\n",
    "    covariance_k = modelParam['sigma']\n",
    "    alpha_k = modelParam['alpha']\n",
    "    m_k = modelParam['m']\n",
    "    k = len(m_k)\n",
    "    \n",
    "    g = np.zeros((m,k))\n",
    "    for j in range(k):\n",
    "        if m_k[j] is not 0:\n",
    "            det_sigma_k = np.linalg.det(covariance_k[j])\n",
    "            sigma_inv = np.linalg.inv(covariance_k[j])\n",
    "            for i in range(m):\n",
    "                X_mu = X[i] - mean_k[j]\n",
    "                g[i,j] = -np.log(det_sigma_k) + np.log(alpha_k[j]) - np.dot(np.dot(X_mu, sigma_inv), X_mu.T)\n",
    "        else:\n",
    "            g[:,j] = -inf * np.ones(m)\n",
    "            \n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Training the Classifier and Testing the Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(data, train_idx, test_idx, class_k, mode, threshold):\n",
    "    (m, n) = data.shape\n",
    "    k = len(class_k)\n",
    "    training_data = data[train_idx]\n",
    "    m_train = len(training_data)\n",
    "    X_train = training_data[:,:n-1].reshape((m_train,n-1))\n",
    "    Y_train = training_data[:,n-1].reshape((m_train,1))\n",
    "    \n",
    "    \n",
    "    #Distribution Model = Gaussian\n",
    "    mean_k = {}\n",
    "    covariance_k = {}\n",
    "    m_train_k = {}\n",
    "    X_train_k = {}\n",
    "    train_idx_k = {}\n",
    "    alpha_k = {}\n",
    "    \n",
    "    #Determining Model Parameters\n",
    "    for i in range(k):\n",
    "        train_idx_k[i] = filter((lambda x : data[:,n-1][x] == class_k[i]), train_idx)\n",
    "        X_train_k[i] = data[:, :n-1][train_idx_k[i]]\n",
    "        m_train_k[i] = len(X_train_k[i])\n",
    "        alpha_k[i] = m_train_k[i]/m_train\n",
    "        if m_train_k[i] is not 0:\n",
    "            mean_k[i] = np.mean(X_train_k[i],axis=0)\n",
    "            X_mu_k = X_train_k[i]-mean_k[i]\n",
    "            covariance_k[i] = np.dot(X_mu_k.T,(X_mu_k))/m_train_k[i]\n",
    "    \n",
    "    #Consolidating Model Parameters\n",
    "    modelParam = {}\n",
    "    modelParam['mean'] = mean_k\n",
    "    modelParam['sigma'] = covariance_k\n",
    "    modelParam['alpha'] = alpha_k\n",
    "    modelParam['m'] = m_train_k\n",
    "    result = {}\n",
    "    \n",
    "    #Compute Membership Function\n",
    "    g_train = computeMembership(X_train, modelParam)\n",
    "    \n",
    "    #Classification\n",
    "    if mode == 0: #For Classification\n",
    "        Y_train_hat = classify(g_train, class_k)\n",
    "    if mode == 1: #For PR Curve\n",
    "        Y_train_hat = np.zeros((m_train,1))\n",
    "        d = g_train[:,0] - g_train[:,1]\n",
    "        for i in range(m_train):\n",
    "            if d[i] > threshold:\n",
    "                Y_train_hat[i] = class_k[0]\n",
    "            else:\n",
    "                Y_train_hat[i] = class_k[1]\n",
    "    \n",
    "    #For Debug Purpose: Computing Training Error\n",
    "    '''\n",
    "    confMatrix = getConfusionMatrix(Y_train, Y_train_hat, class_k)    \n",
    "    precision = getPrecision(confMatrix)\n",
    "    accuracy = getAccuracy(confMatrix)\n",
    "    recall = getRecall(confMatrix)\n",
    "    FMeasure = getFMeasure(precision, recall)\n",
    "    result['ConfusionMatrix'] = confMatrix\n",
    "    result['precision'] = precision\n",
    "    result['accuracy'] = accuracy\n",
    "    result['recall'] = recall\n",
    "    result['FMeasure'] = FMeasure\n",
    "    '''\n",
    "    #Testing\n",
    "    test_data = data[test_idx]\n",
    "    m_test = len(test_data)\n",
    "    X_test = test_data[:,:n-1].reshape((m_test,n-1))\n",
    "    Y_test = test_data[:,n-1].reshape((m_test,1))\n",
    "    result = {}\n",
    "    \n",
    "    #Compute Membership Function\n",
    "    g_test = computeMembership(X_test, modelParam)\n",
    "\n",
    "    #Classification\n",
    "    if mode == 0:\n",
    "        Y_test_hat = classify(g_test, class_k)\n",
    "        result['d'] = g_test[:,0] - g_test[:,1]\n",
    "    if mode == 1:\n",
    "        Y_test_hat = np.zeros((m_test,1))\n",
    "        d = g_test[:,0] - g_test[:,1]\n",
    "        for i in range(m_test):\n",
    "            if d[i] > threshold:\n",
    "                Y_test_hat[i] = class_k[0]\n",
    "            else:\n",
    "                Y_test_hat[i] = class_k[1]\n",
    "\n",
    "    \n",
    "    confMatrix = getConfusionMatrix(Y_test, Y_test_hat, class_k)    \n",
    "    precision = getPrecision(confMatrix)\n",
    "    accuracy = getAccuracy(confMatrix)\n",
    "    recall = getRecall(confMatrix)\n",
    "    FMeasure = getFMeasure(precision, recall)\n",
    "\n",
    "    #Consolidating the results\n",
    "    result['ConfusionMatrix'] = confMatrix\n",
    "    result['precision'] = precision\n",
    "    result['accuracy'] = accuracy\n",
    "    result['recall'] = recall\n",
    "    result['FMeasure'] = FMeasure\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###For Debug purpose only: To view the PR Curve for the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plotPRCurve(data, class_k):\n",
    "    (m, n) = data.shape\n",
    "    k = len(class_k)\n",
    "    #print \"m, n, k\", m, n, k\n",
    "    X_train = data[:,:n-1].reshape((m,n-1))\n",
    "    Y_train = data[:,n-1].reshape((m,1))\n",
    "    \n",
    "    #Distribution Model = Gaussian\n",
    "    mean_k = {}\n",
    "    covariance_k = {}\n",
    "    m_train_k = {}\n",
    "    X_train_k = {}\n",
    "    idx_k = {}\n",
    "    alpha_k = {}\n",
    "    \n",
    "    #Determining Model Parameters\n",
    "    for i in range(k):\n",
    "        idx_k[i] = filter((lambda x : data[:,n-1][x] == class_k[i]), range(m))\n",
    "        X_train_k[i] = data[:, :n-1][idx_k[i]]\n",
    "        m_train_k[i] = len(X_train_k[i])\n",
    "        alpha_k[i] = m_train_k[i]/m\n",
    "        if m_train_k[i] is not 0:\n",
    "            mean_k[i] = np.mean(X_train_k[i],axis=0)\n",
    "            X_mu_k = X_train_k[i]-mean_k[i]\n",
    "            covariance_k[i] = np.dot(X_mu_k.T,(X_mu_k))/m_train_k[i]    \n",
    "    \n",
    "    modelParam = {}\n",
    "    modelParam['mean'] = mean_k\n",
    "    modelParam['sigma'] = covariance_k\n",
    "    modelParam['alpha'] = alpha_k\n",
    "    modelParam['m'] = m_train_k\n",
    "    \n",
    "    #Compute Membership Function\n",
    "    g_train = computeMembership(X_train, modelParam)\n",
    "    \n",
    "    #Classification\n",
    "    Y_train_hat = np.zeros((m,1))\n",
    "    \n",
    "    d = g_train[:,0] - g_train[:,1]\n",
    "    start_d = int(round(np.amin(d)))\n",
    "    stop_d = int(round(np.amax(d)))\n",
    "    #print start_d, stop_d\n",
    "    \n",
    "    precision = np.empty((1,k))\n",
    "    recall = np.empty((1,k))\n",
    "\n",
    "    for j in range(start_d-50, stop_d+50, 10):\n",
    "        for i in range(m):\n",
    "            if d[i] > j:\n",
    "                Y_train_hat[i] = class_k[0]\n",
    "            else:\n",
    "                Y_train_hat[i] = class_k[1]\n",
    "        confMatrix = getConfusionMatrix(Y_train, Y_train_hat, class_k)    \n",
    "        #print \"Confusion Matrix\"\n",
    "        #print confMatrix\n",
    "        p = getPrecision(confMatrix)\n",
    "        #print \"Precision\", p[0]\n",
    "        r = getRecall(confMatrix)\n",
    "        #print \"Recall\", r[0]\n",
    "        precision = np.vstack((precision, p))\n",
    "        recall = np.vstack((recall, r))\n",
    "\n",
    "    precision = precision[1:,:]\n",
    "    recall = recall[1:,:]\n",
    "    #print np.trapz(precision[:,0], dx=0.01, axis=0)\n",
    "    \n",
    "    from sklearn import metrics\n",
    "    from sklearn.metrics import precision_recall_curve\n",
    "    print metrics.auc(precision[:,0], recall[:,0])\n",
    "    \n",
    "    #Plotting Curve\n",
    "    fig=plt.figure(figsize=(15,6))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.set_title('PR Curve')\n",
    "    ax.set_xlim(min(recall[:,0]), 1.1)\n",
    "    ax.set_ylim(0, 1.5)\n",
    "    ax.set_xlabel('Recall')\n",
    "    ax.set_ylabel('Precision')\n",
    "    ax.plot(recall[:,0], precision[:,0], 'ro')\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Main function to perform the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[ 415.   27.]\n",
      " [   6.  233.]]\n",
      "Accuracy\t:\t0.951598465473\n",
      "Precision\t:\t0.931508464593\n",
      "Recall\t\t:\t0.981138376519\n",
      "F-Measure\t:\t0.955679514921\n",
      "AUC\t\t:\t0.740587094816\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3wAAAFRCAYAAAAvua/jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUCZ8kiRJktRQJnySJEmS1FD/CRrUfFTIDOMmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x183ff8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def run(fileName, K):\n",
    "    dataset = getData(fileName)\n",
    "    #dataset = getData1()\n",
    "    (rows, cols) = dataset.shape\n",
    "    class_k = np.unique(dataset[:,cols-1])\n",
    "    k = len(class_k)\n",
    "    #print \"class\", class_k\n",
    "    \n",
    "    CV_idx = KFold(len(dataset), n_folds=K)\n",
    "    i = 0\n",
    "    result = []\n",
    "    \n",
    "    #Gaussian Discriminant Analysis\n",
    "    mode = 0 #Experiment\n",
    "    threshold = 0\n",
    "    \n",
    "    for train_idx, test_idx in CV_idx:\n",
    "        #print len(train_idx), len(test_idx)\n",
    "        result.append(train(dataset, train_idx, test_idx, class_k, mode, threshold))\n",
    "        i+=1\n",
    "    \n",
    "    conf_mat = np.zeros((k, k))\n",
    "    precision = np.empty((1,k))\n",
    "    recall = np.empty((1,k))\n",
    "    d = np.empty((1,2))\n",
    "    accuracy=0\n",
    "    \n",
    "    for j in range(i):\n",
    "        conf_mat = np.add(conf_mat, result[j]['ConfusionMatrix'])\n",
    "        precision = np.vstack((precision, result[j]['precision']))\n",
    "        recall = np.vstack((recall, result[j]['recall']))\n",
    "        accuracy += result[j]['accuracy']\n",
    "        d = np.vstack((d, [np.amin(result[j]['d']), np.amax(result[j]['d'])]))\n",
    "    d = d[1:,:]\n",
    "    start_d = int(round(np.amin(d[:,0])))\n",
    "    stop_d = int(round(np.amax(d[:,1])))\n",
    "    \n",
    "    precision = np.nanmean(precision[1:,:], axis=0)\n",
    "    recall = np.nanmean(recall[1:,:], axis=0)\n",
    "    fMeasure = getFMeasure(precision, recall)\n",
    "    accuracy/=K\n",
    "    \n",
    "    print \"Confusion Matrix\"\n",
    "    print conf_mat\n",
    "    print \"Accuracy\\t:\\t\", accuracy\n",
    "    print \"Precision\\t:\\t\", precision[0]\n",
    "    print \"Recall\\t\\t:\\t\", recall[0]\n",
    "    print \"F-Measure\\t:\\t\", fMeasure[0]\n",
    "    \n",
    "    #For Debug Pupose Only\n",
    "    '''\n",
    "    if cols-1 > 1 and k == 2:\n",
    "        plotPRCurve(dataset, class_k)\n",
    "    '''\n",
    "    \n",
    "    #Plotting Precision-Recall Curve\n",
    "    mode = 1 #PR-Curve Varying Threshold\n",
    "    i = 0\n",
    "    result = []\n",
    "\n",
    "    precision = np.empty((1,k))\n",
    "    recall = np.empty((1,k))\n",
    "    for threshold in range(start_d, stop_d, 25):\n",
    "        for train_idx, test_idx in CV_idx:\n",
    "            result.append(train(dataset, train_idx, test_idx, class_k, mode, threshold))\n",
    "            i+=1\n",
    "    \n",
    "        p = np.empty((1,k))\n",
    "        r = np.empty((1,k))\n",
    "    \n",
    "        for j in range(i):\n",
    "            precision = np.vstack((precision, result[j]['precision']))\n",
    "            recall = np.vstack((recall, result[j]['recall']))\n",
    "    \n",
    "        p = np.nanmean(p[1:,:], axis=0)\n",
    "        r = np.nanmean(r[1:,:], axis=0)\n",
    "        precision = np.vstack((precision, p))\n",
    "        recall = np.vstack((recall, r))\n",
    "        \n",
    "    precision = precision[1:,:]\n",
    "    recall = recall[1:,:]    \n",
    "    tmp = precision[:,0]\n",
    "    tmp = tmp[~np.isnan(tmp)]\n",
    "    print \"AUC\\t\\t:\\t\", np.nanmean(tmp)\n",
    "    \n",
    "    fig=plt.figure(figsize=(15,5))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.set_title('Precision-Recall Curve')\n",
    "    ax.set_xlim(min(recall[:,0]), 1.1)\n",
    "    ax.set_ylim(0, 1.1)\n",
    "    ax.set_xlabel('Recall')\n",
    "    ax.set_ylabel('Precision')\n",
    "    ax.plot(recall[:,0], precision[:,0], 'ro')\n",
    "    #ax.plot(recall[:,1], precision[:,1], 'bs')\n",
    "    ax.scatter(recall[:,0], precision[:,0], marker='o')\n",
    "    \n",
    "    #'''\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    #fileName='Iris'\n",
    "    fileName='Breast-Cancer'\n",
    "    run(fileName,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
