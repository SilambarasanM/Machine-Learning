{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##2. b Multi-Layer Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "%matplotlib inline\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.preprocessing import *\n",
    "from __future__ import division\n",
    "import random\n",
    "import math\n",
    "t=np.seterr(divide='ignore', invalid='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1.0 + np.exp(-1*x))\n",
    "def softmax(x, X):\n",
    "    softMax = np.exp(x)/np.sum(np.exp(X))\n",
    "    return softMax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Neural Network Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, setup):\n",
    "        \n",
    "        #Setting unit counts\n",
    "        self.nX = setup['Input Units'] + 1 \n",
    "        self.nZ = setup['Hidden Units'] + 1\n",
    "        self.nY = setup['Output Units']\n",
    "\n",
    "        #Units\n",
    "        self.x = np.zeros(self.nX)\n",
    "        self.x[0] = 1\n",
    "        \n",
    "        self.z = np.zeros(self.nZ)\n",
    "        self.z[0] = 1\n",
    "        \n",
    "        self.y = np.zeros(self.nY)\n",
    "        self.target = setup['Targets']\n",
    "        \n",
    "        # Weights\n",
    "        self.w = np.zeros((self.nX, self.nZ-1))\n",
    "        \n",
    "        for i in range(self.nX):\n",
    "            for j in range(self.nZ-1):\n",
    "                self.w[i][j] = random.uniform(-0.05, 0.05)\n",
    "        \n",
    "        self.v = np.zeros((self.nZ, self.nY))\n",
    "        \n",
    "        for i in range(self.nZ):\n",
    "            for j in range(self.nY):\n",
    "                self.v[i][j] = random.uniform(-0.05, 0.05)\n",
    "        \n",
    "        # Delta values from previous iteration\n",
    "        self.dw = np.zeros((self.nX, self.nZ-1))\n",
    "        self.dv = np.zeros((self.nZ, self.nY))\n",
    "        \n",
    "\n",
    "    def update(self, inputs):\n",
    "        # input activations\n",
    "        for i in range(1,self.nX):\n",
    "            self.x[i] = inputs[i-1]\n",
    "        \n",
    "        # hidden activations\n",
    "        for j in range(1,self.nZ):\n",
    "            sum = 0.0\n",
    "            for i in range(self.nX):\n",
    "                sum += self.x[i] * self.w[i][j-1]\n",
    "            self.z[j] = sigmoid(sum)\n",
    "\n",
    "        # output activations\n",
    "        scores = np.zeros(self.nY)\n",
    "        for k in range(self.nY):\n",
    "            score = 0.0\n",
    "            for j in range(self.nZ):\n",
    "                score += self.z[j] * self.v[j][k]\n",
    "            scores[k] = score\n",
    "        for k in range(self.nY):\n",
    "            self.y[k] = softmax(scores[k], scores)\n",
    "        \n",
    "        return self.y\n",
    "\n",
    "    def indicator(self, target):\n",
    "        return [1 if self.target[j] == target else 0 for j in range(self.nY)]\n",
    "        \n",
    "    \n",
    "    def backPropagate(self, target, alpha, momentum):\n",
    "        \n",
    "        #Output Units for the target\n",
    "        targets = self.indicator(target)\n",
    "        \n",
    "        # Calculate delta V\n",
    "        v_deltas = np.zeros((self.nZ, self.nY))\n",
    "        error = np.zeros(self.nY)\n",
    "        for j in range(self.nZ):\n",
    "            for k in range(self.nY):\n",
    "                error[k] = self.y[k] - targets[k]\n",
    "                v_deltas[j][k] = error[k] * self.z[j]\n",
    "\n",
    "        # Update V\n",
    "        for j in range(self.nZ):\n",
    "            for k in range(self.nY):\n",
    "                self.v[j][k] = self.v[j][k] - (alpha * v_deltas[j][k] + momentum * self.dv[j][k])\n",
    "                self.dv[j][k] = v_deltas[j][k] \n",
    "        \n",
    "        # Calculate delta W\n",
    "        w_deltas = np.zeros((self.nX, self.nZ-1))\n",
    "        for i in range(self.nX):\n",
    "            sumK = 0.0\n",
    "            for j in range(1,self.nZ):\n",
    "                for k in range(self.nY):\n",
    "                    sumK += error[k] * self.v[j][k] * self.z[j] * (1.0 - self.z[j])\n",
    "                w_deltas[i][j-1] = sumK * self.x[i]\n",
    "\n",
    "        # Update W\n",
    "        for i in range(self.nX):\n",
    "            for j in range(self.nZ-1):\n",
    "                self.w[i][j] = self.w[i][j] - (alpha * w_deltas[i][j] + momentum * self.dw[i][j])\n",
    "                self.dw[i][j] = w_deltas[i][j]\n",
    "\n",
    "        \n",
    "        # calculate error\n",
    "        err = 0.0\n",
    "        for k in range(len(targets)):\n",
    "            err += 0.5 * (error[k]**2)\n",
    "        \n",
    "        return err\n",
    "\n",
    "    def classify(self, y):\n",
    "        return self.target[np.argmax(y)]\n",
    "    \n",
    "    def getConfusionMatrix(self, actual, prediction):\n",
    "        m = len(actual)\n",
    "        cm = np.zeros((self.nY, self.nY))\n",
    "        for i in range(self.nY):\n",
    "            actual_i = filter(lambda x: actual[x] == self.target[i], range(m))\n",
    "            for j in range(self.nY):\n",
    "                predicted_j = filter(lambda x: prediction[x] == self.target[j], range(m))\n",
    "                cm[i,j] = len(np.intersect1d(actual_i, predicted_j))\n",
    "        return cm\n",
    "    \n",
    "    def test(self, data):\n",
    "        error = 0\n",
    "        m = len(data)\n",
    "        estimate = np.zeros(m)\n",
    "\n",
    "        for i in range(m):\n",
    "            estimate[i] = self.classify(self.update(data[i][:-1]))\n",
    "            \n",
    "            if estimate[i] != data[i][-1]:\n",
    "                error+=1\n",
    "        \n",
    "        #print \"Error: \", error\n",
    "        return self.getConfusionMatrix(estimate, data[:,-1])\n",
    "        \n",
    "    def weights(self):\n",
    "        print 'W:'\n",
    "        for i in range(self.nX):\n",
    "            print self.w[i]\n",
    "        print\n",
    "        print 'V:'\n",
    "        for j in range(self.nZ):\n",
    "            print self.v[j]\n",
    "\n",
    "    def train(self, data, iterations, alpha, momentum):\n",
    "        for i in range(iterations):\n",
    "            error = 0.0\n",
    "            \n",
    "            for x in data:\n",
    "                input = x[:-1]\n",
    "                target = x[-1]\n",
    "                #print Y\n",
    "                self.update(input)\n",
    "                error = error + self.backPropagate(target,alpha, momentum)\n",
    "            \n",
    "            #Report Status\n",
    "            #if i % 100 == 0:\n",
    "                #print('error %-.8f' % error)\n",
    "                #print 'X', self.x\n",
    "                #print 'Z', self.z\n",
    "                #print 'Y_hat', self.y\n",
    "                #self.weights()\n",
    "            \n",
    "            #Objective Error\n",
    "            if error <= 0.0001:\n",
    "                #print('error %-.8f' % error)\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Normalize the given dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    \n",
    "    [nrows, ncols] = data.shape\n",
    "\n",
    "    col_mean = np.zeros(ncols-1).reshape(ncols-1, 1)\n",
    "    col_sd = np.zeros(ncols-1).reshape(ncols-1, 1)\n",
    "    normalized_data = data.astype(float64)\n",
    "    \n",
    "    for i in range(ncols-1):\n",
    "        col_mean[i] = np.mean(data[:,i])\n",
    "        col_sd = np.std(data[:,i])\n",
    "        normalized_data[:,i] = [(data[:,i][j] - col_mean[i])/col_sd for j in range(nrows)]\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Calculate Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getAccuracy(matrix):\n",
    "    return np.trace(matrix)/np.sum(matrix)\n",
    "\n",
    "def getPrecision(matrix):\n",
    "    k = len(matrix)\n",
    "    precision = np.zeros(k)\n",
    "    for i in range(k):\n",
    "        actual_positives = np.sum(matrix[i])\n",
    "        precision[i] = matrix[i,i]/actual_positives\n",
    "    return precision\n",
    "\n",
    "def getRecall(matrix):\n",
    "    k = len(matrix)\n",
    "    recall = np.zeros(k)\n",
    "    for i in range(k):\n",
    "        predicted_positives = np.sum(matrix[:,i])\n",
    "        recall[i] = matrix[i,i]/predicted_positives\n",
    "    return recall\n",
    "\n",
    "def getFMeasure(precision, recall):\n",
    "    k = len(precision)\n",
    "    fm = np.zeros(k)\n",
    "    for i in range(k):\n",
    "        fm[i] = 2* precision[i]*recall[i]/(precision[i]+recall[i])\n",
    "    return fm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###SKLearn Implementation MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import *\n",
    "#Dev Code Implementation\n",
    "def inbuilt(train_data, test_data, config):\n",
    "    (m, n) = train_data.shape\n",
    "    X_train = train_data[:,:n-1].reshape((m,n-1))\n",
    "    Y_train = train_data[:,n-1].reshape((m,1))\n",
    "    (m, n) = test_data.shape\n",
    "    X_test = test_data[:,:n-1].reshape((m,n-1))\n",
    "    Y_test = test_data[:,n-1].reshape((m,1))\n",
    "    \n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(config['Hidden Units'],), max_iter=10, algorithm='sgd', \n",
    "                            momentum=config['Momentum'], learning_rate='constant', learning_rate_init=config['Learning Rate'])\n",
    "        \n",
    "    mlp.fit(X_train, Y_train)\n",
    "        \n",
    "    print(\"Training set score: %f\" % mlp.score(X_train, Y_train))\n",
    "    print(\"Test set score: %f\" % mlp.score(X_test, Y_test))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Run the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run(config, data):\n",
    "    \n",
    "    targets = np.unique(data[:,-1])\n",
    "    #print \"Targets\", targets\n",
    "    K = config['K-Fold']\n",
    "    CV_idx = KFold(len(data), n_folds=K)\n",
    "    \n",
    "    \n",
    "    config['Input Units'] = len(data[0]) - 1\n",
    "    config['Targets'] = targets\n",
    "    config['Output Units'] = len(targets)\n",
    "    \n",
    "    \n",
    "    cm = np.zeros((len(targets),len(targets)))\n",
    "    \n",
    "    for train_idx, test_idx in CV_idx:\n",
    "        # Creating MLP\n",
    "        MLP = NeuralNetwork(config)\n",
    "        \n",
    "        # Train\n",
    "        #print \"\\n***Training Begins***\"\n",
    "        MLP.train(data[train_idx], config['Iterations'], config['Learning Rate'], config['Momentum'])\n",
    "    \n",
    "        # Test\n",
    "        #print \"\\n***Testing Begins***\"\n",
    "        cm = np.add(cm, MLP.test(data[test_idx]))\n",
    "        \n",
    "        #In-built Python Library\n",
    "        #inbuilt(data[train_idx],data[test_idx],config)\n",
    "    \n",
    "    precision = getPrecision(cm)\n",
    "    accuracy = getAccuracy(cm)\n",
    "    recall = getRecall(cm)\n",
    "    FMeasure = getFMeasure(precision, recall)\n",
    "    \n",
    "    print \"Confusion Matrix\"\n",
    "    print cm\n",
    "    print \"Accuracy\\t:\\t\", accuracy\n",
    "    print \"Precision\\t:\\t\", precision\n",
    "    print \"Recall\\t\\t:\\t\", recall\n",
    "    print \"F-Measure\\t:\\t\", FMeasure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Get the input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getData(dataset):\n",
    "    if dataset=='Iris':\n",
    "        from sklearn import datasets\n",
    "        data = datasets.load_iris() \n",
    "    \n",
    "        X = data['data']\n",
    "        Y = data['target']\n",
    "        Y = Y.reshape(len(data['target']), 1)\n",
    "        data = np.hstack((X, Y))\n",
    "        data = normalize(data)\n",
    "    elif dataset=='mnist':\n",
    "        from sklearn.datasets import fetch_mldata\n",
    "        data = fetch_mldata('mnist-original', data_home='C:\\\\Users\\\\admin\\\\Anaconda\\\\CS584')\n",
    "        randIdx = np.zeros(1000).astype(int)\n",
    "        for i in range(1000):\n",
    "            randIdx[i] = random.randint(0, 69999)\n",
    "            \n",
    "        Y = data['target']\n",
    "        X = data['data']/255.\n",
    "        Y = Y.reshape(len(Y), 1)\n",
    "        data = np.hstack((X, Y))\n",
    "        data = data[randIdx]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[ 50.   1.   0.]\n",
      " [  0.  45.   2.]\n",
      " [  0.   4.  48.]]\n",
      "Accuracy\t:\t0.953333333333\n",
      "Precision\t:\t[ 0.98039216  0.95744681  0.92307692]\n",
      "Recall\t\t:\t[ 1.    0.9   0.96]\n",
      "F-Measure\t:\t[ 0.99009901  0.92783505  0.94117647]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    config = {\n",
    "        \n",
    "    'Hidden Units'  : 5,\n",
    "    'Learning Rate' : 0.2,\n",
    "    'Momentum'      : 0.7,\n",
    "    'Iterations'    : 100,\n",
    "    'K-Fold'        : 10\n",
    "        \n",
    "    }\n",
    "    \n",
    "    data = getData('Iris')\n",
    "    run(config, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
