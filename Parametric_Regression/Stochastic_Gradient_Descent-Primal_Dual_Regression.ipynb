{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Multivariate Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "%matplotlib inline\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Function to load the data from data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getData(fileName):\n",
    "    strData=[]\n",
    "    with open(fileName,'r') as f:\n",
    "        for line in f:\n",
    "            if line.strip().find('#'):\n",
    "                strData.append(line.strip().split(\" \"))\n",
    "    data = np.array(strData, dtype='|S25').astype(np.float64)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Function to calculate Mean Square Error (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calcErr(Y_est, Y):\n",
    "    m = len(Y)\n",
    "    err=np.zeros(m)\n",
    "    Yavg = np.mean(Y)\n",
    "    for i in range(m):\n",
    "        err[i] = ((Y_est[i] - Y[i])**2)/m \n",
    "    return np.sum(err)/m "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Function to map the dataset to higher order polynomial and fit a regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def poly_fit(training_data, test_data, degree):   \n",
    "    m_train = len(training_data)\n",
    "    X_train = training_data[:,:2].reshape((m_train,2))\n",
    "    Y_train = training_data[:,2].reshape((m_train,1))\n",
    "        \n",
    "    m_test = len(test_data)\n",
    "    X_test = test_data[:,:2].reshape((m_test,2))\n",
    "    Y_test = test_data[:,2].reshape((m_test,1))\n",
    "    \n",
    "    poly = PolynomialFeatures(degree)\n",
    "    Z_train = poly.fit_transform(X_train)\n",
    "    \n",
    "    theta = np.dot(np.linalg.pinv(Z_train),Y_train)\n",
    "    Y_train_est = np.dot(Z_train, theta)\n",
    "    \n",
    "    Z_test = poly.fit_transform(X_test)\n",
    "    Y_test_est = np.dot(Z_test, theta)\n",
    "    \n",
    "    err_train = calcErr(Y_train_est,Y_train)\n",
    "    err_test = calcErr(Y_test_est,Y_test)\n",
    "    \n",
    "    err = [err_train, err_test]\n",
    "    \n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Function to fit a polynomial model using Python library functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def poly_lm_fit(training_data, test_data, degree):     \n",
    "    m_train = len(training_data)\n",
    "    X_train = training_data[:,:2].reshape((m_train,2))\n",
    "    Y_train = training_data[:,2].reshape((m_train,1))\n",
    "        \n",
    "    m_test = len(test_data)\n",
    "    X_test = test_data[:,:2].reshape((m_test,2))\n",
    "    Y_test = test_data[:,2].reshape((m_test,1))\n",
    "    \n",
    "    poly = PolynomialFeatures(degree)\n",
    "    Z_train = poly.fit_transform(X_train)\n",
    "    \n",
    "    lm = LinearRegression()\n",
    "    lm.fit(Z_train,Y_train)    \n",
    "    Y_train_est = lm.predict(Z_train)\n",
    "    \n",
    "    Z_test = poly.fit_transform(X_test)\n",
    "    Y_test_est = lm.predict(Z_test)\n",
    "    \n",
    "    err_train = calcErr(Y_train_est,Y_train)\n",
    "    err_test = calcErr(Y_test_est,Y_test)\n",
    "    \n",
    "    err = [err_train, err_test]\n",
    "    \n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Function to normalize the dataset for Iterative Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normaliza(data):\n",
    "    \n",
    "    [nrows, ncols] = data.shape\n",
    "    \n",
    "    col_mean = np.zeros(ncols).reshape(ncols, 1)\n",
    "    col_sd = np.zeros(ncols).reshape(ncols, 1)\n",
    "    normalized_data = np.zeros(data.shape)\n",
    "    \n",
    "    for i in range(ncols):\n",
    "        col_mean[i] = np.mean(data[:,i])\n",
    "        col_sd = np.std(data[:,i])\n",
    "        nomarlized_data[:,i] = [(data[:,i][j] - col_mean[i])/col_sd for j in range(nrows)]\n",
    "    \n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Function to perform Stochastic Gradient Descent Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def iterative_method(training_data, test_data, degree, theta_0, learning_rate):\n",
    "    \n",
    "    import random\n",
    "    \n",
    "    m_train = len(training_data)\n",
    "    X_train = training_data[:,:2].reshape((m_train,2))\n",
    "    Y_train = training_data[:,2].reshape((m_train,1))\n",
    "    \n",
    "    m_test = len(test_data)\n",
    "    X_test = test_data[:,:2].reshape((m_test,2))\n",
    "    Y_test = test_data[:,2].reshape((m_test,1))\n",
    "    \n",
    "    poly = PolynomialFeatures(degree)\n",
    "    Z_train = poly.fit_transform(X_train)\n",
    "    \n",
    "    n = Z_train.shape[1]\n",
    "    theta_old = np.zeros(n).reshape(n,1)\n",
    "    theta_old.fill(theta_0)\n",
    "    theta = np.zeros(n)\n",
    "    \n",
    "    randomIdx = np.arange(m_train)\n",
    "    random.shuffle(randomIdx)\n",
    "    X_train = X_train[randomIdx]\n",
    "    Y_train= Y_train[randomIdx]\n",
    "    \n",
    "    for i in range(m_train):\n",
    "        for j in range(m_train):\n",
    "            step = learning_rate * (np.dot(Z_train[j], theta_old) - Y_train[j]) * Z_train[j].T\n",
    "            theta = theta_old - step.reshape(n,1)\n",
    "            eps = max(theta_old-theta)\n",
    "            if eps <= 0.0000000001:\n",
    "                break\n",
    "            theta_old = theta\n",
    "        \n",
    "    Y_train_est = np.dot(Z_train, theta)\n",
    "    \n",
    "    Z_test = poly.fit_transform(X_test)\n",
    "    Y_test_est = np.dot(Z_test, theta)\n",
    "    \n",
    "    err_train = calcErr(Y_train_est,Y_train)\n",
    "    err_test = calcErr(Y_test_est,Y_test)\n",
    "    \n",
    "    err = [err_train, err_test]\n",
    "    \n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Function to implement Guassian Kernel function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gaussian_kernel(X, Y, sigma):\n",
    "    m = len(X)\n",
    "    G = np.zeros((m,m))\n",
    "    distance = np.zeros((m,m))\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        for j in range(len(Y[0])):\n",
    "            for k in range(len(Y)):\n",
    "                distance[i,j] += (X[i,k] - Y[k,j])**2\n",
    "            G[i,j] = np.exp((-1/2)*(distance[i,j]/sigma**2))\n",
    "    #print G.shape\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Function to solve the Dual Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dual_regression(training_data, test_data,degree):\n",
    "    m_train = len(training_data)\n",
    "    X_train = training_data[:,:2].reshape((m_train,2))\n",
    "    Y_train = training_data[:,2].reshape((m_train,1))\n",
    "        \n",
    "    m_test = len(test_data)\n",
    "    X_test = test_data[:,:2].reshape((m_test,2))\n",
    "    Y_test = test_data[:,2].reshape((m_test,1))\n",
    "    \n",
    "    poly = PolynomialFeatures(degree)\n",
    "    \n",
    "    Z_train = poly.fit_transform(X_train)    \n",
    "    G_train = gaussian_kernel(Z_train, Z_train.T, 0.1)\n",
    "    alpha = solve(G_train, Y_train)\n",
    "    Y_train_est = np.dot(alpha.T, G_train)\n",
    "    Y_train_est = Y_train_est.T\n",
    "    \n",
    "    Z_test = poly.fit_transform(X_test)\n",
    "    G_test = gaussian_kernel(Z_train, Z_test.T, 0.01)    \n",
    "    Y_test_est = np.dot(alpha.T, G_test)\n",
    "    Y_test_est = Y_test_est.T\n",
    "    \n",
    "    err_train = calcErr(Y_train_est,Y_train)\n",
    "    err_test = calcErr(Y_test_est,Y_test)\n",
    "    \n",
    "    err = [err_train, err_test]\n",
    "    \n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Function to load real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getRealData():\n",
    "    from sklearn import datasets\n",
    "    data = datasets.load_boston() \n",
    "    #data = datasets.load_diabetes()\n",
    "    X = data['data']\n",
    "    Y = data['target']\n",
    "    Y = Y.reshape(len(data['target']), 1)\n",
    "    dataset = np.hstack((X, Y))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Master function that invokes all the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run(fileName, K, degree, theta, alpha):\n",
    "    \n",
    "    if fileName=='real':\n",
    "        dataset = getRealData()\n",
    "    else:\n",
    "        dataset = getData(fileName)\n",
    "    \n",
    "    \n",
    "    #Slicing to use reduced data\n",
    "    dataset = dataset[0:500]\n",
    "    \n",
    "    #K = 2\n",
    "    #degree = 6\n",
    "    #theta_0 = 0.3\n",
    "    #learning_rate = 0.1\n",
    "    \n",
    "    CV_idx = KFold(len(dataset), n_folds=K)\n",
    "    err_poly_train = np.zeros(K)\n",
    "    err_poly_test = np.zeros(K)\n",
    "    err_poly_lm_train = np.zeros(K)\n",
    "    err_poly_lm_test = np.zeros(K)\n",
    "    err_dual_train = np.zeros(K)\n",
    "    err_dual_test = np.zeros(K)\n",
    "    err_iter_train = np.zeros(K)\n",
    "    err_iter_test = np.zeros(K)\n",
    "    time_taken_primal = []\n",
    "    time_taken_dual = []\n",
    "    \n",
    "    normalized_dataset = normalize(dataset.reshape((len(dataset),len(dataset[0]))))\n",
    "    \n",
    "    i = 0\n",
    "    for train_idx, test_idx in CV_idx:\n",
    "        start_primal = datetime.now()\n",
    "        [err_poly_train[i], err_poly_test[i]] = poly_fit(dataset[train_idx], dataset[test_idx], degree)\n",
    "        stop_primal = datetime.now()\n",
    "        \n",
    "        [err_poly_lm_train[i], err_poly_lm_test[i]] = poly_lm_fit(dataset[train_idx], dataset[test_idx], degree)\n",
    "        \n",
    "        start_dual = datetime.now()\n",
    "        [err_dual_train[i], err_dual_test[i]] = dual_regression(dataset[train_idx], dataset[test_idx],degree)\n",
    "        stop_dual = datetime.now()\n",
    "        time_taken_primal.append(stop_primal - start_primal)\n",
    "        time_taken_dual.append(stop_dual - start_dual)\n",
    "        \n",
    "        [err_iter_train[i], err_iter_test[i]] = iterative_method(\n",
    "            normalized_dataset[train_idx], normalized_dataset[test_idx],degree, theta, alpha)\n",
    "        \n",
    "        i+=1 \n",
    "        \n",
    "    t_primal = 0\n",
    "    t_dual = 0\n",
    "    \n",
    "    for i in range(K):\n",
    "        t_primal += time_taken_primal[i].total_seconds()\n",
    "        t_dual += time_taken_dual[i].total_seconds()\n",
    "            \n",
    "    print \"\\t\\t\\t\\t\\t <Training Error> <Test Error>\"\n",
    "    print \"Polynomial Model Errors: \\t\\t\", np.mean(err_poly_train), np.mean(err_poly_test)\n",
    "    print \"Python Polynomial Model Errors: \\t\", np.mean(err_poly_lm_train), np.mean(err_poly_lm_test)\n",
    "    \n",
    "    print \"\\nExplicit Model Errors: \\t\\t\\t\", np.mean(err_poly_train), np.mean(err_poly_test)\n",
    "    print \"Iterative Method Errors: \\t\\t\", np.mean(err_iter_train), np.mean(err_iter_test)\n",
    "    \n",
    "    print \"\\nPrimal Model Errors: \\t\\t\\t\", np.mean(err_poly_train), np.mean(err_poly_test), \"<Time Elapsed: \", t_primal/K, \"s >\"\n",
    "    print \"Dual Model Errors: \\t\\t\\t\", np.mean(err_dual_train), np.mean(err_dual_test), \"<Time Elapsed: \", t_dual/K, \"s >\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Main function that performs Multivariate Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\t\t <Training Error> <Test Error>\n",
      "Polynomial Model Errors: \t\t0.00342084100209 0.0342322596925\n",
      "Python Polynomial Model Errors: \t0.00342084100209 0.0342322596925\n",
      "\n",
      "Explicit Model Errors: \t\t\t0.00342084100209 0.0342322596925\n",
      "Iterative Method Errors: \t\t0.000696065985947 0.00633241469444\n",
      "\n",
      "Primal Model Errors: \t\t\t0.00342084100209 0.0342322596925 <Time Elapsed:  0.0161 s >\n",
      "Dual Model Errors: \t\t\t1.57225102888e-34 0.032718579732 <Time Elapsed:  15.675 s >\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    realData = 'real'\n",
    "    #fileName = realData\n",
    "    fileName = 'mvar-set4.dat'\n",
    "    \n",
    "    run(fileName, K = 10, degree = 5, theta = 0.3, alpha = 0.01) \n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
